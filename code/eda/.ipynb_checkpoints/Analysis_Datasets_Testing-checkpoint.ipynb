{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# author: Jerry Tsai\n",
    "# program make_anly_sets.py\n",
    "# creation date: 2016-05-03\n",
    "# version 1.0\n",
    "#\n",
    "# PURPOSE: Make several analysis data sets from the data in the\n",
    "#   Upwork provider profiles data (text file)\n",
    "#\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def json_prep(in_file):\n",
    "    '''\n",
    "    Create pandas dataframe from text file of JSON strings\n",
    "    '''\n",
    "    # read the entire file `ainto a python array\n",
    "    with open(in_file, 'rb') as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    # remove the trailing \"\\n\" from each line\n",
    "    data = map(lambda x: x.rstrip(), data)\n",
    "\n",
    "    # each element of 'data' is an individual JSON object.\n",
    "    # i want to convert it into an *array* of JSON objects\n",
    "    # which, in and of itself, is one large JSON object\n",
    "    # basically... add square brackets to the beginning\n",
    "    # and end, and have all the individual business JSON objects\n",
    "    # separated by a comma\n",
    "    data_json_str = \"[\" + ','.join(data) + \"]\"\n",
    "\n",
    "    data_list_of_dicts = json.loads(data_json_str)\n",
    "\n",
    "    out_df = pd.read_json(data_json_str)\n",
    "    return out_df\n",
    "\n",
    "def triage(dict_, level=0):\n",
    "    '''\n",
    "    Visualize JSON data\n",
    "    \"Pretty Print\" data, showing nesting via indentation\n",
    "    '''\n",
    "    if not(isinstance(dict_, float) or isinstance(dict_, basestring)):\n",
    "        print type(dict_)\n",
    "        for key, val in dict_.iteritems():\n",
    "            print ' '*level*2, key\n",
    "            if isinstance(val, dict):\n",
    "                triage(val, level=level+1)\n",
    "            elif isinstance(val, list):\n",
    "                for index, item in enumerate(val):\n",
    "                    print ' '*level*2, 'item', index\n",
    "                    triage(item, level=level+1)\n",
    "            elif isinstance(val, basestring):\n",
    "                print ' '*(level+1)*2, '=', val\n",
    "\n",
    "\n",
    "# ## Make pandas DataFrame out of detailed profiles data for exploration\n",
    "\n",
    "profiles_df = json_prep('../../data/detailed_profiles_da_2.txt')\n",
    "\n",
    "# ## Clean up and mung profiles data\n",
    "\n",
    "# Drop agency information. Not going to attempt to assign effect to agency due to low participation frequency in agencies in general and most agencies have few people, so will not have sufficient power.\n",
    "profiles_df.drop(['ag_cny_recno', 'ag_country', 'ag_country_tz', \\\n",
    "                  'ag_description', 'ag_logo', 'ag_name', 'ag_recent_hours', \\\n",
    "                  'ag_total_hours', 'agency_ciphertext' \\\n",
    "                 ], axis=1, inplace=True)\n",
    "\n",
    "# Drop redundant variables.\n",
    "profiles_df.drop(['dev_portrait_100', 'dev_portrait_32', 'dev_portrait_50', 'dev_recno'                     ], axis=1, inplace=True)\n",
    "\n",
    "# Drop obviously or inherently irrelevant variables.\n",
    "profiles_df.drop(['dev_ui_profile_access', 'permalink'], axis=1, inplace=True)\n",
    "\n",
    "# Drop variables with data leak.\n",
    "profiles_df.drop(['dev_adj_score', 'dev_adj_score_recent', \\\n",
    "                  'dev_billed_assignments', 'dev_last_activity', 'dev_last_worked', \\\n",
    "                  'dev_last_worked_ts', 'dev_portfolio_items_count', 'dev_tot_feedback', \\\n",
    "                  'dev_total_hours'], axis=1, inplace=True)\n",
    "\n",
    "# Drop variables that may be good to use, but for which I do not currently have the time to work up.\n",
    "\n",
    "profiles_df.drop(['dev_city', 'dev_first_name', \\\n",
    "                  'dev_last_name',  'dev_short_name' \\\n",
    "                 ], axis=1, inplace=True)\n",
    "\n",
    "# Drop variables that seem useful, but do not appear to someone looking at the profile, so are therefore non-factors in evaluating the profile.\n",
    "profiles_df.drop(['dev_job_categories_v2', 'job_categories' \\\n",
    "                 ], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JerryTsai/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/JerryTsai/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ciphertext == dev_recno_ciphertext\n"
     ]
    }
   ],
   "source": [
    "### CREATE DERIVED VARIABLES\n",
    "\n",
    "# `ciphertext` and `dev_recno_ciphertext`\n",
    "equality_of_ciphertext = profiles_df['ciphertext'] == profiles_df['dev_recno_ciphertext']\n",
    "\n",
    "if all(equality_of_ciphertext) == True:\n",
    "    print 'All ciphertext == dev_recno_ciphertext'\n",
    "    profiles_df.drop(['ciphertext'], axis=1, inplace=True)\n",
    "\n",
    "# `dev_ac_agencies`: presence or absence\n",
    "profiles_df['agency_affl'] = profiles_df['dev_ac_agencies'] <> ''\n",
    "\n",
    "# `dev_bill_rate`: WILL LEAVE ALONE\n",
    "\n",
    "# `dev_blurb`: WILL LEAVE ALONE\n",
    "\n",
    "# `dev_country`: leaving it alone for now, will study it in the analysis\n",
    "\n",
    "# CODE TO EXAMINE dev_country\n",
    "# def pct_freq(series):\n",
    "#     return 1. * series.value_counts() / len(series)\n",
    "# print pct_freq(profiles_df['dev_country'])\n",
    "\n",
    "# CODE TO EXAMINE dev_eng_skill\n",
    "# `dev_eng_skill`: leaving it alone for now, will study it in the analysis\n",
    "# profiles_df.dev_eng_skill.value_counts(dropna=False)\n",
    "\n",
    "# `dev_groups`\n",
    "profiles_df['group_affl'] = profiles_df['dev_groups'] <> ''\n",
    "# Check work\n",
    "# print profiles_df['group_affl'].value_counts(dropna=True)\n",
    "\n",
    "# Examine agency and group membership\n",
    "# pd.crosstab(profiles_df['agency_affl'], profiles_df['group_affl'], dropna=False)\n",
    "\n",
    "# `dev_portrait`: presence or absence\n",
    "profiles_df['has_portrait'] = profiles_df['dev_portrait'] <> ''\n",
    "# profiles_df['has_portrait'].value_counts(dropna=True)\n",
    "\n",
    "# `dev_profile_title`: leaving it alone, will study it in the analysis\n",
    "# profiles_df['dev_profile_title'][:5]\n",
    "\n",
    "# `dev_timezone`: leaving it alone, will study it in the analysis\n",
    "profiles_df['dev_timezone'].value_counts(dropna=True)\n",
    "\n",
    "\n",
    "### \"MULTI\"-VARIABLES (I.E., NESTED JSON VARIABLES)\n",
    "\n",
    "def grab_data(datalist, creature, id_, list_of_keys):\n",
    "    if isinstance(creature, basestring):\n",
    "        pass\n",
    "    elif isinstance(creature, dict):\n",
    "        tuple_to_add = tuple([id_] + [creature.get(key, '') for key in list_of_keys])\n",
    "        datalist.append(tuple_to_add)\n",
    "    elif isinstance(creature, list):\n",
    "        for creature_item in creature:\n",
    "            tuple_to_add = tuple([id_] + [creature_item.get(key, '') for key in list_of_keys])\n",
    "            datalist.append(tuple_to_add)\n",
    "\n",
    "\n",
    "### GOING THROUGH EACH \"MULTI\"-VARs\n",
    "\n",
    "# ### `assignments`:\n",
    "\n",
    "### CREATE LIST OF TUPLES ABOUT JOBS\n",
    "jobs_tuples = list()\n",
    "\n",
    "key_list = ['as_opening_title', 'as_from_full', 'as_to_full', \\\n",
    "            'as_rate', 'as_total_hours_precise', 'as_total_charge', \\\n",
    "            'as_job_type' \\\n",
    "            ]\n",
    "\n",
    "for index, assignments_tuple in \\\n",
    "  enumerate(profiles_df[['dev_recno_ciphertext', 'assignments']].itertuples(index=False)):\n",
    "    profile_id = assignments_tuple[0]\n",
    "    assignments = assignments_tuple[1]\n",
    "    if 'hr' in assignments:\n",
    "        hr_assignments = assignments['hr']\n",
    "        if 'job' in hr_assignments:\n",
    "            grab_data(jobs_tuples, hr_assignments['job'], profile_id, key_list)\n",
    "        elif 'assignment' in hr_assignments:\n",
    "            grab_data(jobs_tuples, hr_assignments['assignment'], profile_id, key_list)\n",
    "\n",
    "    if 'fp' in assignments:\n",
    "        fp_assignments = assignments['fp']\n",
    "        if 'job' in fp_assignments:\n",
    "            grab_data(jobs_tuples, fp_assignments['job'], profile_id, key_list)\n",
    "        elif 'assignment' in fp_assignments:\n",
    "            grab_data(jobs_tuples, fp_assignments['assignment'], profile_id, key_list)\n",
    "\n",
    "### MAKE PANDAS DATAFRAME FROM LIST OF TUPLES\n",
    "jobs_df = pd.DataFrame(jobs_tuples)\n",
    "jobs_df.columns = ['dev_recno_ciphertext'] + key_list\n",
    "\n",
    "# CHECK WORK\n",
    "# jobs_df['dev_recno_ciphertext'].nunique()\n",
    "\n",
    "\n",
    "### MAKE PANDAS DATAFRAME FOR HOURLY PAID JOBS DATA\n",
    "def blank_or_zero(str):\n",
    "    if str == '':\n",
    "        return True\n",
    "    else:\n",
    "        match = re.search(r'\\d+.*\\d*', str)\n",
    "        number = float(match.group())\n",
    "        if number == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def get_number(str):\n",
    "    return float(re.search(r'\\d+.*\\d*', str).group())\n",
    "\n",
    "hr_paid_jobs_df = jobs_df[(jobs_df['as_job_type'] == 'Hourly') & ~(jobs_df['as_rate'].apply(blank_or_zero))]\n",
    "\n",
    "### DROP VARIABLES THAT WON'T BE USED\n",
    "hr_paid_jobs_df.drop(['as_opening_title', 'as_job_type'], axis=1, inplace=True)\n",
    "hr_paid_jobs_df['rate_as_number'] = jobs_df['as_rate'].apply(blank_or_zero)\n",
    "\n",
    "# hr_paid_jobs.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ### `education`:\n",
    "\n",
    "def degree_categ(str):\n",
    "    if 'master' in str.lower():\n",
    "        return 'Master'\n",
    "    elif 'bachelor' in str.lower():\n",
    "        return 'Bachelor'\n",
    "    elif 'doctor' in str.lower():\n",
    "        return 'Doctor'\n",
    "    elif 'b.' in str.lower():\n",
    "        return 'Bachelor'\n",
    "    elif 'm.' in str.lower():\n",
    "        return 'Master'\n",
    "    elif 'mba' in str.lower():\n",
    "        return 'Master'\n",
    "    elif 'msc' in str.lower():\n",
    "        return 'Master'\n",
    "    elif 'bsc' in str.lower():\n",
    "        return 'Bachelor'\n",
    "    elif 'bs' in str.lower():\n",
    "        return 'Bachelor'\n",
    "    elif 'ba ' in str.lower():\n",
    "        return 'Bachelor'\n",
    "    elif 'ms' in str.lower():\n",
    "        return 'Master'\n",
    "    elif 'ma' in str.lower():\n",
    "        return 'Master'\n",
    "    elif 'phd' in str.lower():\n",
    "        return 'Doctor'\n",
    "    elif 'ph.d' in str.lower():\n",
    "        return 'Doctor'\n",
    "    elif 'engineer' in str.lower():\n",
    "        return 'Engineer'\n",
    "    else:\n",
    "        return 'Other'\n",
    "vect_deg_cat = np.vectorize(degree_categ)\n",
    "\n",
    "def degree_score(ed_degree):\n",
    "    if degree_categ(ed_degree) == 'Bachelor':\n",
    "        return 1\n",
    "    elif degree_categ(ed_degree) == 'Engineer':\n",
    "        return 2\n",
    "    elif degree_categ(ed_degree) == 'Master':\n",
    "        return 3\n",
    "    elif degree_categ(ed_degree) == 'Doctor':\n",
    "        return 4\n",
    "    elif degree_categ(ed_degree) == 'Other':\n",
    "        return 0\n",
    "\n",
    "def grab_max_data(datalist, creature, id_, max_func, key_to_be_maxed, list_of_keys):\n",
    "    if isinstance(creature, basestring):\n",
    "        tuple_to_add = tuple((id_, 'Other'))\n",
    "    elif isinstance(creature, dict):\n",
    "        tuple_to_add = tuple([id_] + [creature.get(key, '') for key in list_of_keys])\n",
    "        datalist.append(tuple_to_add)\n",
    "    elif isinstance(creature, list):\n",
    "        curr_score = -1\n",
    "        for creature_item in creature:\n",
    "            score = max_func(creature_item.get(key_to_be_maxed, ''))\n",
    "            if score > curr_score:\n",
    "                tuple_to_beat = tuple([id_] + [creature_item.get(key, '') for key in list_of_keys])\n",
    "                curr_score = score\n",
    "        tuple_to_add = tuple_to_beat\n",
    "        datalist.append(tuple_to_add)\n",
    "\n",
    "### CREATE EDUCATION TUPLES, RETURNING HIGHEST DEGREE ACHIEVED FOR EACH PERSON\n",
    "degrees_tuples = list()\n",
    "for index, education_tuple in \\\n",
    "  enumerate(profiles_df[['dev_recno_ciphertext', 'education']].itertuples(index=False)):\n",
    "    profile_id = education_tuple[0]\n",
    "    schools = education_tuple[1]\n",
    "    if isinstance(schools, basestring):\n",
    "        degrees_tuples.append((profile_id, 'Other'))\n",
    "    else:\n",
    "        for key in schools.keys():\n",
    "            if key == u'institution':\n",
    "                school_institution = schools['institution']\n",
    "                grab_max_data(degrees_tuples, school_institution, profile_id, degree_score, 'ed_degree', ['ed_degree'])\n",
    "\n",
    "# CHECK WORK\n",
    "# for index, tup in enumerate(degrees_tuples):\n",
    "#     print tup\n",
    "#     if index > 4: break\n",
    "\n",
    "\n",
    "### CREATE DATA FRAME INDICATING HIGHEST DEGREE ACHIEVED\n",
    "###   AND ADD `highest_degree` to analysis data set\n",
    "degrees_df = pd.DataFrame(degrees_tuples)\n",
    "degrees_df.columns = ['dev_recno_ciphertext'] + ['highest_degree']\n",
    "\n",
    "profiles_df['highest_degree'] = degrees_df['highest_degree']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    32428\n",
      "True      7553\n",
      "Name: has_portfolio, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ### `experiences` will be skipped because of uncertain usefulness and lack of time\n",
    "\n",
    "# ### `portfolio_items`: presence or absence\n",
    "profiles_df['has_portfolio'] = profiles_df['portfolio_items'] <> ''\n",
    "print profiles_df['has_portfolio'].value_counts(dropna=True)\n",
    "\n",
    "# ### `tsexams`: presence or absence\n",
    "\n",
    "profiles_df['took_tests'] = profiles_df['tsexams'] <> ''\n",
    "profiles_df['took_tests'].value_counts(dropna=True)\n",
    "\n",
    "# ### `skills`\n",
    "### CREATE LIST OF TUPLES ABOUT SKILLS\n",
    "skills_tuples = list()\n",
    "key_list = ['skl_name']\n",
    "\n",
    "for index, skills_tuple in enumerate(profiles_df[['dev_recno_ciphertext', 'skills']].itertuples(index=False)):\n",
    "    profile_id = skills_tuple[0]\n",
    "    skills = skills_tuple[1]\n",
    "    skills_list = list()\n",
    "    if 'skill' in skills:\n",
    "        grab_data(skills_tuples, skills['skill'], profile_id, key_list)\n",
    "\n",
    "### CREATE PANDAS DATA FRAME FROM LIST OF TUPLES\n",
    "skills_df = pd.DataFrame(skills_tuples)\n",
    "skills_df.columns = ['dev_recno_ciphertext'] + key_list\n",
    "\n",
    "### MODIFY SKILLS SO THAT CountVectorizer TREATS THEM AS SINGLE WORDS\n",
    "###  AND NOT AS MULTIPLE WORDS OR ONE-LETTER CHARACTERS TO IGNORE\n",
    "def multiple_replace(dict, text):\n",
    "    # Make one-letter skills longer\n",
    "    if text == 'c':\n",
    "        longtext = 'cprog'\n",
    "    elif text == 'r':\n",
    "        longtext = 'rprog'\n",
    "    elif text == 's':\n",
    "        longtext = 'sprog'\n",
    "    else:\n",
    "        longtext = text\n",
    "\n",
    "    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "\n",
    "    # For each match, look-up corresponding value in dictionary\n",
    "    return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], longtext)\n",
    "\n",
    "substitution_dict = {\n",
    "    '+': 'plus',\n",
    "    '#': 'sharp',\n",
    "    '/': 'slash',\n",
    "    '-': 'dash',\n",
    "    '.': 'dot'\n",
    "}\n",
    "\n",
    "def contiguous_word(skill):\n",
    "    return multiple_replace(substitution_dict, skill)\n",
    "\n",
    "### CREATE PROFILE-LEVEL SKILLS VARIABLE ('skills_string')\n",
    "###   TO FEED INTO CountVectorizer\n",
    "skills_content_list = list()\n",
    "key_list = ['skills_string']\n",
    "start_tuple_number = 0\n",
    "end_tuple_number = len(skills_tuples) - 1\n",
    "\n",
    "for index, skills_tuple in enumerate(skills_tuples):\n",
    "    if index == start_tuple_number:\n",
    "        curr_ciphertext = skills_tuple[0]\n",
    "        skills_string = contiguous_word(skills_tuple[1])\n",
    "    elif curr_ciphertext == skills_tuple[0]:\n",
    "        skills_string += (' ' + contiguous_word(skills_tuple[1]) )\n",
    "    elif curr_ciphertext <> skills_tuple[0]:\n",
    "        skills_content_list.append((curr_ciphertext, skills_string))\n",
    "        curr_ciphertext = skills_tuple[0]\n",
    "        skills_string = contiguous_word(skills_tuple[1])\n",
    "\n",
    "    if index == end_tuple_number:\n",
    "        skills_content_list.append((curr_ciphertext, skills_string))\n",
    "\n",
    "\n",
    "### CREATE PANDAS DATAFRAME\n",
    "skills_content_df = pd.DataFrame(skills_content_list)\n",
    "skills_content_df.columns = ['dev_recno_ciphertext'] + key_list\n",
    "\n",
    "### ADD `skills_string` to PROFILES DATAFRAME\n",
    "profiles_df['skills_string'] = skills_content_df['skills_string']\n",
    "\n",
    "skill_vectorizer = CountVectorizer()\n",
    "sv_sparse_matrix = skill_vectorizer.fit_transform(profiles_df['skills_string'])\n",
    "\n",
    "# CHECK WORK\n",
    "# frequencies = sum(sv_sparse_matrix).toarray()[0]\n",
    "# check_work = pd.DataFrame(frequencies, index=skill_vectorizer.get_feature_names(), columns=['frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skills_vectorized_df = pd.DataFrame(sv_sparse_matrix.todense())\n",
    "skills_vectorized_df.columns = list(skill_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Drop variables from which other variables have been derived.\n",
    "profiles_df.drop([ \\\n",
    "                  'dev_ac_agencies', 'dev_groups', \\\n",
    "                  'dev_is_affiliated' \\\n",
    "                  ], axis=1, inplace=True)\n",
    "\n",
    "# ### Drop aggregate variables\n",
    "profiles_df.drop([ \\\n",
    "                 'assignments', 'experiences', 'portfolio_items', 'skills', 'tsexams' \\\n",
    "                 ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### MAKE PICKLES OF NEW DATAFRAMES\n",
    "outfile_skills_vectorized = 'data/_skills_vectorized_df.pkl'\n",
    "outfile_profiles = 'data/profiles_df.pkl'\n",
    "outfile_jobs = 'data/jobs_df.pkl'\n",
    "outfile_hr_paid_jobs = 'data/hr_paid_jobs_df.pkl'\n",
    "outfile_skills = 'data/skills_df.pkl'\n",
    "\n",
    "outfile_list = [ \\\n",
    "outfile_skills_vectorized, \\\n",
    "outfile_profiles, \\\n",
    "outfile_jobs, \\\n",
    "outfile_hr_paid_jobs, \\\n",
    "outfile_skills \\\n",
    "]\n",
    "\n",
    "out_df_list = [ \\\n",
    "skills_vectorized_df, \\\n",
    "profiles_df, \\\n",
    "jobs_df, \\\n",
    "hr_paid_jobs_df, \\\n",
    "skills_df \\\n",
    "]\n",
    "\n",
    "for index, outfile in enumerate(outfile_list):\n",
    "    f = open(outfile, 'wb')\n",
    "    pickle.dump(out_df_list[index], f)\n",
    "    f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
